# Pipeline ETL - Servicios Backend

Arquitectura de servicios para procesamiento paralelo del Pipeline ETL con soporte multiusuario.

## Estructura de Carpetas

```
server/services/
‚îú‚îÄ‚îÄ orchestration/          # Servicios de orquestaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ DependencyResolver.js   # Resoluci√≥n de dependencias (topological sort)
‚îÇ   ‚îú‚îÄ‚îÄ WorkerPool.js           # Pool de workers paralelos
‚îÇ   ‚îú‚îÄ‚îÄ PipelineOrchestrator.js # [PENDIENTE] Orquestador principal
‚îÇ   ‚îî‚îÄ‚îÄ index.js
‚îú‚îÄ‚îÄ pipeline/               # Servicios del pipeline
‚îÇ   ‚îú‚îÄ‚îÄ BasePipelineService.js  # Clase base para todos los servicios
‚îÇ   ‚îú‚îÄ‚îÄ IPAService.js           # [PENDIENTE] Servicio IPA
‚îÇ   ‚îú‚îÄ‚îÄ CAPMService.js          # [PENDIENTE] Servicio CAPM
‚îÇ   ‚îú‚îÄ‚îÄ DerivadosService.js     # [PENDIENTE] Servicio Derivados
‚îÇ   ‚îú‚îÄ‚îÄ PNLService.js           # [PENDIENTE] Servicio PNL
‚îÇ   ‚îî‚îÄ‚îÄ UBSService.js           # [PENDIENTE] Servicio UBS
‚îî‚îÄ‚îÄ tracking/               # Servicios de tracking y logging
    ‚îú‚îÄ‚îÄ ExecutionTracker.js     # Tracking de estados de ejecuci√≥n
    ‚îú‚îÄ‚îÄ LoggingService.js       # Sistema de logging estructurado
    ‚îî‚îÄ‚îÄ index.js
```

## Configuraci√≥n

### pipeline.config.yaml

Archivo de configuraci√≥n central que define:
- Servicios del pipeline y sus dependencias
- L√≠mites de concurrencia (fondos y tareas)
- Stored procedures y su orden de ejecuci√≥n
- Estrategias de retry y manejo de errores
- Tracking de estados

**Ubicaci√≥n**: `server/config/pipeline.config.yaml`

### database.js

Configuraci√≥n del connection pool ajustado para soportar procesamiento paralelo masivo:
- **Max connections**: 200 (antes: 10)
- **Min connections**: 20 (antes: 0)
- Soporta m√∫ltiples ejecuciones con 100+ fondos simult√°neos cada una

## Servicios de Orquestaci√≥n

### DependencyResolver

Calcula el orden de ejecuci√≥n correcto usando algoritmo topol√≥gico (Kahn).

**Uso**:
```javascript
const resolver = new DependencyResolver(services);
const order = resolver.getExecutionOrder(); // ['EXTRACCION', 'VALIDACION', ...]
const canRun = resolver.canExecute('PROCESS_CAPM', completedServices);
```

### WorkerPool

Gestiona ejecuci√≥n paralela con l√≠mite de concurrencia.

**Uso**:
```javascript
const pool = new WorkerPool(8); // M√°ximo 8 tareas concurrentes
const result = await pool.enqueue(() => myAsyncTask(), { fundId: 123 });
await pool.waitForCompletion();
```

## Servicios del Pipeline

### BasePipelineService

Clase base abstracta que proporciona:
- Ejecuci√≥n de SPs con manejo de errores
- Retry logic con exponential backoff
- Logging estructurado
- Tracking de estado
- Validaciones

**Patr√≥n de uso**:
```javascript
class IPAService extends BasePipelineService {
  async execute(context) {
    // L√≥gica espec√≠fica o usar implementaci√≥n base
    return super.execute(context);
  }
}
```

### Servicios Espec√≠ficos [PENDIENTE]

- **IPAService**: Procesamiento IPA (7 SPs secuenciales)
- **CAPMService**: Procesamiento CAPM (3 SPs)
- **DerivadosService**: Procesamiento Derivados (4 SPs)
- **PNLService**: Procesamiento PNL (5 SPs)
- **UBSService**: Procesamiento UBS (3 SPs)

## Servicios de Tracking

### ExecutionTracker

Gestiona estados de ejecuci√≥n en tablas `logs.Ejecuciones` y `logs.Ejecucion_Fondos`.

**Uso**:
```javascript
const tracker = new ExecutionTracker(pool);
await tracker.initializeExecution(idEjecucion, fechaReporte, fondos);
await tracker.updateFundState(idEjecucion, idFund, 'Estado_Process_IPA', 'EN_PROGRESO');
await tracker.markFundCompleted(idEjecucion, idFund, duration);
```

### LoggingService

Sistema de logging estructurado con bulk insert.

**Uso**:
```javascript
const logger = new LoggingService(pool, 'INFO');
await logger.info(idEjecucion, idFund, 'PROCESS_IPA', 'Iniciando procesamiento...');
await logger.error(idEjecucion, idFund, 'PROCESS_IPA', 'Error cr√≠tico', error);
await logger.flush(); // Forzar escritura
```

**Caracter√≠sticas**:
- Bulk insert (batch de 100 logs)
- Auto-flush cada 5 segundos
- Niveles: DEBUG, INFO, WARNING, ERROR
- Logging a consola configurable

## Scripts de Base de Datos

### 01_enable_read_committed_snapshot.sql

Habilita READ_COMMITTED_SNAPSHOT para reducir deadlocks en ~80%.

```sql
ALTER DATABASE Inteligencia_Producto_Dev
SET READ_COMMITTED_SNAPSHOT ON WITH ROLLBACK IMMEDIATE;
```

### 02_create_indexes_execution_logs.sql

Optimiza tabla de logs para INSERT y queries r√°pidos.

```sql
CREATE CLUSTERED INDEX IX_EjecucionLogs_Ejecucion_Timestamp
ON logs.Ejecucion_Logs (ID_Ejecucion, Timestamp);
```

## Estrategia de Aislamiento

### Tablas Temporales por Fondo

**Naming convention**:
```
#temp_[TABLA]_[ID_Ejecucion]_[ID_Fund]

Ejemplos:
#temp_IPA_WorkTable_12345_789
#temp_CAPM_WorkTable_12345_456
```

**Ventajas**:
- ‚úÖ Aislamiento total entre fondos y ejecuciones
- ‚úÖ Auto-cleanup al cerrar conexi√≥n
- ‚úÖ Sin conflictos de escritura
- ‚úÖ Paralelizaci√≥n m√°xima

## Estado de Implementaci√≥n

### ‚úÖ Fase 1 Completada (Semana 1)
- [x] Habilitar READ_COMMITTED_SNAPSHOT
- [x] Aumentar connection pool a 200 (paralelizaci√≥n masiva)
- [x] Crear √≠ndices en logs.Ejecucion_Logs
- [x] Implementar DependencyResolver
- [x] Implementar WorkerPool
- [x] Implementar BasePipelineService
- [x] Implementar ExecutionTracker
- [x] Implementar LoggingService
- [x] Crear pipeline.config.yaml (sin l√≠mites de concurrencia)

### üîÑ Pr√≥ximos Pasos (Fase 2 - Semana 2)
- [ ] Refactorizar SPs del grupo IPA (7 SPs con sufijo _v2)
- [ ] Implementar IPAService.js
- [ ] Testing unitario de SPs
- [ ] Test de integraci√≥n end-to-end

## M√©tricas de √âxito

**Objetivos**:
- Reducci√≥n de 70-80% en tiempo total de procesamiento (paralelizaci√≥n masiva)
- Soportar m√∫ltiples ejecuciones simult√°neas sin degradaci√≥n
- Procesar 100+ fondos en paralelo por ejecuci√≥n (sin l√≠mite configurado)
- < 1 deadlock por d√≠a (gracias a READ_COMMITTED_SNAPSHOT)
- 99.9% uptime
- Capacidad: 200 conexiones SQL simult√°neas, 2000 tareas en paralelo

## Referencias

- **Plan completo**: `~/.claude/plans/linked-mixing-karp.md`
- **Configuraci√≥n**: `server/config/pipeline.config.yaml`
- **Scripts BD**: `database/scripts/`
